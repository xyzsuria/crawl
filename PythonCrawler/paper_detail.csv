标题,学科,当前版本,作者,摘要,主题,通讯作者+历史版本
What Makes Good In-Context Examples for GPT-?,Computer Science > Computation and Language,[Submitted on 17 Jan 2021],"Authors:Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, Weizhu Chen","Abstract: GPT-$3$ has attracted lots of attention due to its superior performance across a wide range of NLP tasks, especially with its powerful and versatile in-context few-shot learning ability. Despite its success, we found that the empirical results of GPT-$3$ depend heavily on the choice of in-context examples. In this work, we investigate whether there are more effective strategies for judiciously selecting in-context examples (relative to random sampling) that better leverage GPT-$3$'s few-shot capabilities. Inspired by the recent success of leveraging a retrieval module to augment large-scale neural network models, we propose to retrieve examples that are semantically-similar to a test sample to formulate its corresponding prompt. Intuitively, the in-context examples selected with such a strategy may serve as more informative inputs to unleash GPT-$3$'s extensive knowledge. We evaluate the proposed approach on several natural language understanding and generation benchmarks, where the retrieval-based prompt selection approach consistently outperforms the random baseline. Moreover, it is observed that the sentence encoders fine-tuned on task-related datasets yield even more helpful retrieval results. Notably, significant gains are observed on tasks such as table-to-text generation (41.9% on the ToTTo dataset) and open-domain question answering (45.5% on the NQ dataset). We hope our investigation could help understand the behaviors of GPT-$3$ and large-scale pre-trained LMs in general and enhance their few-shot capabilities.",Computation and Language (cs.CL),"Submission history
From: Jiachang Liu [view email]
[v1] Sun, 17 Jan 2021 23:38:40 UTC (110 KB)"
"How contextual are contextualized word representations? comparing the geometry of BERT, ELMo, and GPT-2 embeddings",Computer Science > Computation and Language,[Submitted on 2 Sep 2019],Authors:Kawin Ethayarajh,"Abstract: Replacing static word embeddings with contextualized word representations has yielded significant improvements on many NLP tasks. However, just how contextual are the contextualized representations produced by models such as ELMo and BERT? Are there infinitely many context-specific representations for each word, or are words essentially assigned one of a finite number of word-sense representations? For one, we find that the contextualized representations of all words are not isotropic in any layer of the contextualizing model. While representations of the same word in different contexts still have a greater cosine similarity than those of two different words, this self-similarity is much lower in upper layers. This suggests that upper layers of contextualizing models produce more context-specific representations, much like how upper layers of LSTMs produce more task-specific representations. In all layers of ELMo, BERT, and GPT-2, on average, less than 5% of the variance in a word's contextualized representations can be explained by a static embedding for that word, providing some justification for the success of contextualized representations.",Computation and Language (cs.CL),"Submission history
From: Kawin Ethayarajh [view email]
[v1] Mon, 2 Sep 2019 01:51:46 UTC (178 KB)"
"GPT understands, too",Computer Science > Computation and Language,[Submitted on 18 Mar 2021],"Authors:Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, Jie Tang","Abstract: While GPTs with traditional fine-tuning fail to achieve strong results on natural language understanding (NLU), we show that GPTs can be better than or comparable to similar-sized BERTs on NLU tasks with a novel method P-tuning -- which employs trainable continuous prompt embeddings. On the knowledge probing (LAMA) benchmark, the best GPT recovers 64\% (P@1) of world knowledge without any additional text provided during test time, which substantially improves the previous best by 20+ percentage points. On the SuperGlue benchmark, GPTs achieve comparable and sometimes better performance to similar-sized BERTs in supervised learning. Importantly, we find that P-tuning also improves BERTs' performance in both few-shot and supervised settings while largely reducing the need for prompt engineering. Consequently, P-tuning outperforms the state-of-the-art approaches on the few-shot SuperGlue benchmark.",Computation and Language (cs.CL),"Submission history
From: Xiao Liu [view email]
[v1] Thu, 18 Mar 2021 17:13:50 UTC (1,192 KB)"
Sparks of artificial general intelligence: Early experiments with gpt-4,Computer Science > Computation and Language,"[Submitted on 22 Mar 2023 (v1), last revised 13 Apr 2023 (this version, v5)]","Authors:Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, Yi Zhang","Abstract: Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions.",Computation and Language (cs.CL),"Submission history
From: Sebastien Bubeck [view email]
[v1] Wed, 22 Mar 2023 16:51:28 UTC (13,667 KB)
[v2] Fri, 24 Mar 2023 17:07:43 UTC (6,453 KB)
[v3] Mon, 27 Mar 2023 22:36:40 UTC (6,470 KB)
[v4] Wed, 12 Apr 2023 17:00:10 UTC (12,943 KB)
[v5] Thu, 13 Apr 2023 20:41:31 UTC (6,476 KB)"
"Hello, it's GPT-2--how can I help you? towards the use of pretrained language models for task-oriented dialogue systems",Computer Science > Computation and Language,"[Submitted on 12 Jul 2019 (v1), last revised 4 Aug 2019 (this version, v2)]","Authors:Paweł Budzianowski, Ivan Vulić","Abstract: Data scarcity is a long-standing and crucial challenge that hinders quick development of task-oriented dialogue systems across multiple domains: task-oriented dialogue models are expected to learn grammar, syntax, dialogue reasoning, decision making, and language generation from absurdly small amounts of task-specific data. In this paper, we demonstrate that recent progress in language modeling pre-training and transfer learning shows promise to overcome this problem. We propose a task-oriented dialogue model that operates solely on text input: it effectively bypasses explicit policy and language generation modules. Building on top of the TransferTransfo framework (Wolf et al., 2019) and generative model pre-training (Radford et al., 2019), we validate the approach on complex multi-domain task-oriented dialogues from the MultiWOZ dataset. Our automatic and human evaluations show that the proposed model is on par with a strong task-specific neural baseline. In the long run, our approach holds promise to mitigate the data scarcity problem, and to support the construction of more engaging and more eloquent task-oriented conversational agents.",Computation and Language (cs.CL),"Submission history
From: Paweł Budzianowski [view email]
[v1] Fri, 12 Jul 2019 14:55:06 UTC (707 KB)
[v2] Sun, 4 Aug 2019 10:44:47 UTC (707 KB)"
A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?,Computer Science > Artificial Intelligence,[Submitted on 21 Mar 2023],"Authors:Chaoning Zhang, Chenshuang Zhang, Sheng Zheng, Yu Qiao, Chenghao Li, Mengchun Zhang, Sumit Kumar Dam, Chu Myaet Thwal, Ye Lin Tun, Le Luang Huy, Donguk kim, Sung-Ho Bae, Lik-Hang Lee, Yang Yang, Heng Tao Shen, In So Kweon, Choong Seon Hong","Abstract: As ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has made headlines everywhere because of its ability to analyze and create text, images, and beyond. With such overwhelming media coverage, it is almost impossible for us to miss the opportunity to glimpse AIGC from a certain angle. In the era of AI transitioning from pure analysis to creation, it is worth noting that ChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks. Impressed by the capability of the ChatGPT, many people are wondering about its limits: can GPT-5 (or other future GPT variants) help ChatGPT unify all AIGC tasks for diversified content creation? Toward answering this question, a comprehensive review of existing AIGC tasks is needed. As such, our work comes to fill this gap promptly by offering a first look at AIGC, ranging from its techniques to applications. Modern generative AI relies on various technical foundations, ranging from model architecture and self-supervised pretraining to generative modeling methods (like GAN and diffusion models). After introducing the fundamental techniques, this work focuses on the technological development of various AIGC tasks based on their output type, including text, images, videos, 3D content, etc., which depicts the full potential of ChatGPT's future. Moreover, we summarize their significant applications in some mainstream industries, such as education and creativity content. Finally, we discuss the challenges currently faced and present an outlook on how generative AI might evolve in the near future.",Artificial Intelligence (cs.AI),"Submission history
From: Chaoning Zhang [view email]
[v1] Tue, 21 Mar 2023 10:09:47 UTC (9,718 KB)"
Gpt-neox-20b: An open-source autoregressive language model,Computer Science > Computation and Language,[Submitted on 14 Apr 2022],"Authors:Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel Weinbach","Abstract: We introduce GPT-NeoX-20B, a 20 billion parameter autoregressive language model trained on the Pile, whose weights will be made freely and openly available to the public through a permissive license. It is, to the best of our knowledge, the largest dense autoregressive model that has publicly available weights at the time of submission. In this work, we describe \model{}'s architecture and training and evaluate its performance on a range of language-understanding, mathematics, and knowledge-based tasks. We find that GPT-NeoX-20B is a particularly powerful few-shot reasoner and gains far more in performance when evaluated five-shot than similarly sized GPT-3 and FairSeq models. We open-source the training and evaluation code, as well as the model weights, at this https URL.",Computation and Language (cs.CL),"Submission history
From: Stella Biderman [view email]
[v1] Thu, 14 Apr 2022 04:00:27 UTC (6,828 KB)"
The radicalization risks of GPT-3 and advanced neural language models,,,,,,
GPT-too: A language-model-first approach for AMR-to-text generation,Computer Science > Computation and Language,"[Submitted on 18 May 2020 (v1), last revised 27 May 2020 (this version, v2)]","Authors:Manuel Mager, Ramon Fernandez Astudillo, Tahira Naseem, Md Arafat Sultan, Young-Suk Lee, Radu Florian, Salim Roukos","Abstract: Meaning Representations (AMRs) are broad-coverage sentence-level semantic graphs. Existing approaches to generating text from AMR have focused on training sequence-to-sequence or graph-to-sequence models on AMR annotated data only. In this paper, we propose an alternative approach that combines a strong pre-trained language model with cycle consistency-based re-scoring. Despite the simplicity of the approach, our experimental results show these models outperform all previous techniques on the English LDC2017T10dataset, including the recent use of transformer architectures. In addition to the standard evaluation metrics, we provide human evaluation experiments that further substantiate the strength of our approach.",Computation and Language (cs.CL),"Submission history
From: Manuel Mager [view email]
[v1] Mon, 18 May 2020 22:50:26 UTC (35 KB)
[v2] Wed, 27 May 2020 11:24:29 UTC (36 KB)"
How good are gpt models at machine translation? a comprehensive evaluation,Computer Science > Computation and Language,[Submitted on 18 Feb 2023],"Authors:Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, Hany Hassan Awadalla","Abstract: Generative Pre-trained Transformer (GPT) models have shown remarkable capabilities for natural language generation, but their performance for machine translation has not been thoroughly investigated. In this paper, we present a comprehensive evaluation of GPT models for machine translation, covering various aspects such as quality of different GPT models in comparison with state-of-the-art research and commercial systems, effect of prompting strategies, robustness towards domain shifts and document-level translation. We experiment with eighteen different translation directions involving high and low resource languages, as well as non English-centric translations, and evaluate the performance of three GPT models: ChatGPT, GPT3.5 (text-davinci-003), and text-davinci-002. Our results show that GPT models achieve very competitive translation quality for high resource languages, while having limited capabilities for low resource languages. We also show that hybrid approaches, which combine GPT models with other translation systems, can further enhance the translation quality. We perform comprehensive analysis and human evaluation to further understand the characteristics of GPT translations. We hope that our paper provides valuable insights for researchers and practitioners in the field and helps to better understand the potential and limitations of GPT models for translation.",Computation and Language (cs.CL),"Submission history
From: Hany Hassan Awadalla [view email]
[v1] Sat, 18 Feb 2023 02:11:36 UTC (11,292 KB)"
Want to reduce labeling cost? GPT-3 can help,Computer Science > Computation and Language,[Submitted on 30 Aug 2021],"Authors:Shuohang Wang, Yang Liu, Yichong Xu, Chenguang Zhu, Michael Zeng","Abstract: Data annotation is a time-consuming and labor-intensive process for many NLP tasks. Although there exist various methods to produce pseudo data labels, they are often task-specific and require a decent amount of labeled data to start with. Recently, the immense language model GPT-3 with 175 billion parameters has achieved tremendous improvement across many few-shot learning tasks. In this paper, we explore ways to leverage GPT-3 as a low-cost data labeler to train other models. We find that, to make the downstream model achieve the same performance on a variety of NLU and NLG tasks, it costs 50% to 96% less to use labels from GPT-3 than using labels from humans. Furthermore, we propose a novel framework of combining pseudo labels from GPT-3 with human labels, which leads to even better performance with limited labeling budget. These results present a cost-effective data labeling methodology that is generalizable to many practical applications.",Computation and Language (cs.CL),"Submission history
From: Shuohang Wang [view email]
[v1] Mon, 30 Aug 2021 19:18:24 UTC (4,719 KB)"
Locating and editing factual knowledge in gpt,,,,,,
Instruction tuning with gpt-4,Computer Science > Computation and Language,[Submitted on 6 Apr 2023],"Authors:Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, Jianfeng Gao","Abstract: Prior work has shown that finetuning large language models (LLMs) using machine-generated instruction-following data enables such models to achieve remarkable zero-shot capabilities on new tasks, and no human-written instructions are needed. In this paper, we present the first attempt to use GPT-4 to generate instruction-following data for LLM finetuning. Our early experiments on instruction-tuned LLaMA models show that the 52K English and Chinese instruction-following data generated by GPT-4 leads to superior zero-shot performance on new tasks to the instruction-following data generated by previous state-of-the-art models. We also collect feedback and comparison data from GPT-4 to enable a comprehensive evaluation and reward model training. We make our data generated using GPT-4 as well as our codebase publicly available.",Computation and Language (cs.CL),"Submission history
From: Baolin Peng [view email]
[v1] Thu, 6 Apr 2023 17:58:09 UTC (1,397 KB)"
Automatic text summarization of covid-19 medical research articles using bert and gpt-2,Computer Science > Computation and Language,[Submitted on 3 Jun 2020],"Authors:Virapat Kieuvongngam, Bowen Tan, Yiming Niu","Abstract: With the COVID-19 pandemic, there is a growing urgency for medical community to keep up with the accelerating growth in the new coronavirus-related literature. As a result, the COVID-19 Open Research Dataset Challenge has released a corpus of scholarly articles and is calling for machine learning approaches to help bridging the gap between the researchers and the rapidly growing publications. Here, we take advantage of the recent advances in pre-trained NLP models, BERT and OpenAI GPT-2, to solve this challenge by performing text summarization on this dataset. We evaluate the results using ROUGE scores and visual inspection. Our model provides abstractive and comprehensive information based on keywords extracted from the original articles. Our work can help the the medical community, by providing succinct summaries of articles for which the abstract are not already available.",Computation and Language (cs.CL),"Submission history
From: Virapat Kieuvongngam [view email]
[v1] Wed, 3 Jun 2020 00:54:44 UTC (1,090 KB)"
Learning to answer by learning to ask: Getting the best of gpt-2 and bert worlds,Computer Science > Computation and Language,[Submitted on 6 Nov 2019],"Authors:Tassilo Klein, Moin Nabi","Abstract: Automatic question generation aims at the generation of questions from a context, with the corresponding answers being sub-spans of the given passage. Whereas, most of the methods mostly rely on heuristic rules to generate questions, more recently also neural network approaches have been proposed. In this work, we propose a variant of the self-attention Transformer network architectures model to generate meaningful and diverse questions. To this end, we propose an easy to use model consisting of the conjunction of the Transformer decoder GPT-2 model with Transformer encoder BERT for the downstream task for question answering. The model is trained in an end-to-end fashion, where the language model is trained to produce a question-answer-aware input representation that facilitates to generate an answer focused question. Our result of neural question generation from text on the SQuAD 1.1 dataset suggests that our method can produce semantically correct and diverse questions. Additionally, we assessed the performance of our proposed method for the downstream task of question answering. The analysis shows that our proposed generation & answering collaboration framework relatively improves both tasks and is particularly powerful in the semi-supervised setup. The results further suggest a robust and comparably lean pipeline facilitating question generation in the small-data regime.",Computation and Language (cs.CL),"Submission history
From: Tassilo Klein [view email]
[v1] Wed, 6 Nov 2019 13:23:41 UTC (772 KB)"
Detecting hate speech with gpt-3,Computer Science > Computation and Language,"[Submitted on 23 Mar 2021 (v1), last revised 24 Mar 2022 (this version, v4)]","Authors:Ke-Li Chiu, Annie Collins, Rohan Alexander","Abstract: Sophisticated language models such as OpenAI's GPT-3 can generate hateful text that targets marginalized groups. Given this capacity, we are interested in whether large language models can be used to identify hate speech and classify text as sexist or racist. We use GPT-3 to identify sexist and racist text passages with zero-, one-, and few-shot learning. We find that with zero- and one-shot learning, GPT-3 can identify sexist or racist text with an average accuracy between 55 per cent and 67 per cent, depending on the category of text and type of learning. With few-shot learning, the model's accuracy can be as high as 85 per cent. Large language models have a role to play in hate speech detection, and with further development they could eventually be used to counter hate speech.",Computation and Language (cs.CL),"Submission history
From: Rohan Alexander [view email]
[v1] Tue, 23 Mar 2021 09:17:22 UTC (72 KB)
[v2] Thu, 4 Nov 2021 15:31:09 UTC (53 KB)
[v3] Wed, 16 Mar 2022 13:14:51 UTC (58 KB)
[v4] Thu, 24 Mar 2022 16:24:54 UTC (59 KB)"
Is GPT-3 text indistinguishable from human text? scarecrow: A framework for scrutinizing machine text,Computer Science > Computation and Language,"[Submitted on 2 Jul 2021 (v1), last revised 7 Mar 2022 (this version, v3)]","Authors:Yao Dou, Maxwell Forbes, Rik Koncel-Kedziorski, Noah A. Smith, Yejin Choi","Abstract: Modern neural language models can produce remarkably fluent and grammatical text. So much, in fact, that recent work by Clark et al. (2021) has reported that conventional crowdsourcing can no longer reliably distinguish between machine-authored (GPT-3) and human-authored writing. As errors in machine generations become ever subtler and harder to spot, it poses a new challenge to the research community for robust machine text evaluation. We propose a new framework called Scarecrow for scrutinizing machine text via crowd annotation. To support the broad range of real machine errors that can be identified by laypeople, the ten error categories of Scarecrow -- such as redundancy, commonsense errors, and incoherence -- are identified through several rounds of crowd annotation experiments without a predefined ontology. We then use Scarecrow to collect over 41k error spans in human-written and machine-generated paragraphs of English language news text. We isolate factors for detailed analysis, including parameter count, training data, and various decoding-time configurations. Our approach successfully quantifies measurable gaps between human authored text and generations from models of several sizes, including fourteen configurations of GPT-3. In addition, our analysis unveils new insights, with detailed rationales provided by laypeople, e.g., that the commonsense capabilities have been improving with larger models while math capabilities have not, and that the choices of simple decoding hyperparameters can make remarkable differences on the perceived quality of machine text. We release our training material, annotation toolkit and dataset at this https URL.",Computation and Language (cs.CL),"Submission history
From: Yao Dou [view email]
[v1] Fri, 2 Jul 2021 22:37:03 UTC (9,992 KB)
[v2] Tue, 6 Jul 2021 21:40:39 UTC (9,992 KB)
[v3] Mon, 7 Mar 2022 22:34:20 UTC (10,001 KB)"
"Heroes, Villains, and Victims, and GPT-3--Automated Extraction of Character Roles Without Training Data",Computer Science > Computation and Language,"[Submitted on 16 May 2022 (v1), last revised 17 May 2022 (this version, v2)]","Authors:Dominik Stammbach, Maria Antoniak, Elliott Ash","Abstract: This paper shows how to use large-scale pre-trained language models to extract character roles from narrative texts without training data. Queried with a zero-shot question-answering prompt, GPT-3 can identify the hero, villain, and victim in diverse domains: newspaper articles, movie plot summaries, and political speeches.",Computation and Language (cs.CL),"Submission history
From: Dominik Stammbach [view email]
[v1] Mon, 16 May 2022 10:08:11 UTC (53 KB)
[v2] Tue, 17 May 2022 08:09:51 UTC (49 KB)"
Improving Short Text Classification With Augmented Data Using GPT-3,Computer Science > Computation and Language,[Submitted on 23 May 2022],"Authors:Salvador Balkus, Donghui Yan","Abstract: GPT-3 is a large-scale natural language model developed by OpenAI that can perform many different tasks, including topic classification. Although researchers claim that it requires only a small number of in-context examples to learn a task, in practice GPT-3 requires these training examples to be either of exceptional quality or a higher quantity than easily created by hand. To address this issue, this study teaches GPT-3 to classify whether a question is related to data science by augmenting a small training set with additional examples generated by GPT-3 itself. This study compares two classifiers: the GPT-3 Classification Endpoint with augmented examples, and the GPT-3 Completion Endpoint with an optimal training set chosen using a genetic algorithm. We find that while the augmented Completion Endpoint achieves upwards of 80 percent validation accuracy, using the augmented Classification Endpoint yields more consistent accuracy on unseen examples. In this way, giving large-scale machine learning models like GPT-3 the ability to propose their own additional training examples can result in improved classification performance.",Computation and Language (cs.CL),"Submission history
From: Salvador Balkus [view email]
[v1] Mon, 23 May 2022 01:10:38 UTC (1,437 KB)"
Towards the Generation of Musical Explanations with GPT-3,Computer Science > Computation and Language,[Submitted on 11 May 2022],"Authors:Stephen James Krol, Maria Teresa Llano, Jon McCormack","Abstract: Open AI's language model, GPT-3, has shown great potential for many NLP tasks, with applications in many different domains. In this work we carry out a first study on GPT-3's capability to communicate musical decisions through textual explanations when prompted with a textual representation of a piece of music. Enabling a dialogue in human-AI music partnerships is an important step towards more engaging and creative human-AI interactions. Our results show that GPT-3 lacks the necessary intelligence to really understand musical decisions. A major barrier to reach a better performance is the lack of data that includes explanations of the creative process carried out by artists for musical pieces. We believe such a resource would aid the understanding and collaboration with AI music systems.",Computation and Language (cs.CL),"Submission history
From: Maria Teresa Llano [view email]
[v1] Wed, 11 May 2022 13:04:54 UTC (480 KB)"
Evaluation of GPT and BERT-based models on identifying protein-protein interactions in biomedical text,Computer Science > Computation and Language,[Submitted on 30 Mar 2023],"Authors:Hasin Rehana, Nur Bengisu Çam, Mert Basmaci, Yongqun He, Arzucan Özgür, Junguk Hur","Abstract: Detecting protein-protein interactions (PPIs) is crucial for understanding genetic mechanisms, disease pathogenesis, and drug design. However, with the fast-paced growth of biomedical literature, there is a growing need for automated and accurate extraction of PPIs to facilitate scientific knowledge discovery. Pre-trained language models, such as generative pre-trained transformer (GPT) and bidirectional encoder representations from transformers (BERT), have shown promising results in natural language processing (NLP) tasks. We evaluated the PPI identification performance of various GPT and BERT models using a manually curated benchmark corpus of 164 PPIs in 77 sentences from learning language in logic (LLL). BERT-based models achieved the best overall performance, with PubMedBERT achieving the highest precision (85.17%) and F1-score (86.47%) and BioM-ALBERT achieving the highest recall (93.83%). Despite not being explicitly trained for biomedical texts, GPT-4 achieved comparable performance to the best BERT models with 83.34% precision, 76.57% recall, and 79.18% F1-score. These findings suggest that GPT models can effectively detect PPIs from text data and have the potential for use in biomedical literature mining tasks.",Computation and Language (cs.CL),"Submission history
From: Junguk Hur [view email]
[v1] Thu, 30 Mar 2023 22:06:10 UTC (624 KB)"
BIM-GPT: a Prompt-Based Virtual Assistant Framework for BIM Information Retrieval,Computer Science > Computation and Language,[Submitted on 18 Apr 2023],"Authors:Junwen Zheng, Martin Fischer","Abstract: Efficient information retrieval (IR) from building information models (BIMs) poses significant challenges due to the necessity for deep BIM knowledge or extensive engineering efforts for automation. We introduce BIM-GPT, a prompt-based virtual assistant (VA) framework integrating BIM and generative pre-trained transformer (GPT) technologies to support NL-based IR. A prompt manager and dynamic template generate prompts for GPT models, enabling interpretation of NL queries, summarization of retrieved information, and answering BIM-related questions. In tests on a BIM IR dataset, our approach achieved 83.5% and 99.5% accuracy rates for classifying NL queries with no data and 2% data incorporated in prompts, respectively. Additionally, we validated the functionality of BIM-GPT through a VA prototype for a hospital building. This research contributes to the development of effective and versatile VAs for BIM IR in the construction industry, significantly enhancing BIM accessibility and reducing engineering efforts and training data requirements for processing NL queries.",Computation and Language (cs.CL),"Submission history
From: Junwen Zheng [view email]
[v1] Tue, 18 Apr 2023 22:46:02 UTC (3,448 KB)"
Towards Zero-Shot and Few-Shot Table Question Answering using GPT-3,Computer Science > Machine Learning,[Submitted on 31 Oct 2022],"Authors:Pragya Srivastava, Tanuja Ganu, Saikat Guha","Abstract: We present very early results on using GPT-3 to perform question answering on tabular data. We find that stock pre-trained GPT-3 is able to zero-shot learn the table structure from a serialized JSON array-of-arrays representation, and able to answer lookup queries and simple comparison questions in natural language without any fine-tuning. We further find that simple prompt engineering to include few-shot static Q&A examples significantly improves accuracy. Lastly, we find that intermixing passage text improves accuracy even further on heterogeneous data. We apply our approach on a novel dataset of simple tables in newspaper infographics with promising results. Overall, we find much cause for optimism in this basic approach.",Machine Learning (cs.LG),"Submission history
From: Pragya Srivastava [view email]
[v1] Mon, 31 Oct 2022 13:08:55 UTC (1,336 KB)"
An Analysis of GPT-3's Performance in Grammatical Error Correction,Computer Science > Computation and Language,[Submitted on 25 Mar 2023],"Authors:Steven Coyne, Keisuke Sakaguchi","Abstract: GPT-3 models are very powerful, achieving high performance on a variety of natural language processing tasks. However, there is a relative lack of detailed published analysis on how well they perform on the task of grammatical error correction (GEC). To address this, we perform experiments testing the capabilities of a GPT-3 model (text-davinci-003) against major GEC benchmarks, comparing the performance of several different prompts, including a comparison of zero-shot and few-shot settings. We analyze intriguing or problematic outputs encountered with different prompt formats. We report the performance of our best prompt on the BEA-2019 and JFLEG datasets using a combination of automatic metrics and human evaluations, revealing interesting differences between the preferences of human raters and the reference-based automatic metrics.",Computation and Language (cs.CL),"Submission history
From: Steven Coyne [view email]
[v1] Sat, 25 Mar 2023 03:08:49 UTC (29 KB)"
GPT-2C: A GPT-2 parser for Cowrie honeypot logs,Computer Science > Cryptography and Security,"[Submitted on 14 Sep 2021 (v1), last revised 15 Sep 2021 (this version, v2)]","Authors:Febrian Setianto, Erion Tsani, Fatima Sadiq, Georgios Domalis, Dimitris Tsakalidis, Panos Kostakos","Abstract: Deception technologies like honeypots produce comprehensive log reports, but often lack interoperability with EDR and SIEM technologies. A key bottleneck is that existing information transformation plugins perform well on static logs (e.g. geolocation), but face limitations when it comes to parsing dynamic log topics (e.g. user-generated content). In this paper, we present a run-time system (GPT-2C) that leverages large pre-trained models (GPT-2) to parse dynamic logs generate by a Cowrie SSH honeypot. Our fine-tuned model achieves 89\% inference accuracy in the new domain and demonstrates acceptable execution latency.",Cryptography and Security (cs.CR),"Submission history
From: Febrian Setianto [view email]
[v1] Tue, 14 Sep 2021 11:33:04 UTC (2,091 KB)
[v2] Wed, 15 Sep 2021 06:33:01 UTC (2,091 KB)"
GPT detectors are biased against non-native English writers,Computer Science > Computation and Language,"[Submitted on 6 Apr 2023 (v1), last revised 18 Apr 2023 (this version, v2)]","Authors:Weixin Liang, Mert Yuksekgonul, Yining Mao, Eric Wu, James Zou","Abstract: The rapid adoption of generative language models has brought about substantial advancements in digital communication, while simultaneously raising concerns regarding the potential misuse of AI-generated content. Although numerous detection methods have been proposed to differentiate between AI and human-generated content, the fairness and robustness of these detectors remain underexplored. In this study, we evaluate the performance of several widely-used GPT detectors using writing samples from native and non-native English writers. Our findings reveal that these detectors consistently misclassify non-native English writing samples as AI-generated, whereas native writing samples are accurately identified. Furthermore, we demonstrate that simple prompting strategies can not only mitigate this bias but also effectively bypass GPT detectors, suggesting that GPT detectors may unintentionally penalize writers with constrained linguistic expressions. Our results call for a broader conversation about the ethical implications of deploying ChatGPT content detectors and caution against their use in evaluative or educational settings, particularly when they may inadvertently penalize or exclude non-native English speakers from the global discourse.",Computation and Language (cs.CL),"Submission history
From: Weixin Liang [view email]
[v1] Thu, 6 Apr 2023 01:51:15 UTC (1,273 KB)
[v2] Tue, 18 Apr 2023 22:59:26 UTC (1,564 KB)"
GPT-PINN: Generative Pre-Trained Physics-Informed Neural Networks toward non-intrusive Meta-learning of parametric PDEs,Mathematics > Numerical Analysis,"[Submitted on 27 Mar 2023 (v1), last revised 11 Apr 2023 (this version, v2)]","Authors:Yanlai Chen, Shawn Koohy","Abstract: Physics-Informed Neural Network (PINN) has proven itself a powerful tool to obtain the numerical solutions of nonlinear partial differential equations (PDEs) leveraging the expressivity of deep neural networks and the computing power of modern heterogeneous hardware. However, its training is still time-consuming, especially in the multi-query and real-time simulation settings, and its parameterization often overly excessive. In this paper, we propose the Generative Pre-Trained PINN (GPT-PINN) to mitigate both challenges in the setting of parametric PDEs. GPT-PINN represents a brand-new meta-learning paradigm for parametric systems. As a network of networks, its outer-/meta-network is hyper-reduced with only one hidden layer having significantly reduced number of neurons. Moreover, its activation function at each hidden neuron is a (full) PINN pre-trained at a judiciously selected system configuration. The meta-network adaptively ``learns'' the parametric dependence of the system and ``grows'' this hidden layer one neuron at a time. In the end, by encompassing a very small number of networks trained at this set of adaptively-selected parameter values, the meta-network is capable of generating surrogate solutions for the parametric system across the entire parameter domain accurately and efficiently.",Numerical Analysis (math.NA),"Submission history
From: Yanlai Chen [view email]
[v1] Mon, 27 Mar 2023 02:22:09 UTC (6,013 KB)
[v2] Tue, 11 Apr 2023 16:19:57 UTC (6,018 KB)"
Implicit causality in GPT-2: a case study,Computer Science > Computation and Language,[Submitted on 8 Dec 2022],"Authors:Hien Huynh, Tomas O. Lentz, Emiel van Miltenburg","Abstract: This case study investigates the extent to which a language model (GPT-2) is able to capture native speakers' intuitions about implicit causality in a sentence completion task. We first reproduce earlier results (showing lower surprisal values for pronouns that are congruent with either the subject or object, depending on which one corresponds to the implicit causality bias of the verb), and then examine the effects of gender and verb frequency on model performance. Our second study examines the reasoning ability of GPT-2: is the model able to produce more sensible motivations for why the subject VERBed the object if the verbs have stronger causality biases? We also developed a methodology to avoid human raters being biased by obscenities and disfluencies generated by the model.",Computation and Language (cs.CL),"Submission history
From: Emiel van Miltenburg [view email]
[v1] Thu, 8 Dec 2022 15:42:38 UTC (6,521 KB)"
"ArguGPT: evaluating, understanding and identifying argumentative essays generated by GPT models",Computer Science > Computation and Language,[Submitted on 16 Apr 2023],"Authors:Yikang Liu, Ziyin Zhang, Wanyang Zhang, Shisen Yue, Xiaojing Zhao, Xinyuan Cheng, Yiwen Zhang, Hai Hu","Abstract: AI generated content (AIGC) presents considerable challenge to educators around the world. Instructors need to be able to detect such text generated by large language models, either with the naked eye or with the help of some tools. There is also growing need to understand the lexical, syntactic and stylistic features of AIGC. To address these challenges in English language teaching, we first present ArguGPT, a balanced corpus of 4,038 argumentative essays generated by 7 GPT models in response to essay prompts from three sources: (1) in-class or homework exercises, (2) TOEFL and (3) GRE writing tasks. Machine-generated texts are paired with roughly equal number of human-written essays with three score levels matched in essay prompts. We then hire English instructors to distinguish machine essays from human ones. Results show that when first exposed to machine-generated essays, the instructors only have an accuracy of 61% in detecting them. But the number rises to 67% after one round of minimal self-training. Next, we perform linguistic analyses of these essays, which show that machines produce sentences with more complex syntactic structures while human essays tend to be lexically more complex. Finally, we test existing AIGC detectors and build our own detectors using SVMs and RoBERTa. Results suggest that a RoBERTa fine-tuned with the training set of ArguGPT achieves above 90% accuracy in both essay- and sentence-level classification. To the best of our knowledge, this is the first comprehensive analysis of argumentative essays produced by generative large language models. Machine-authored essays in ArguGPT and our models will be made publicly available at this https URL",Computation and Language (cs.CL),"Submission history
From: Yikang Liu [view email]
[v1] Sun, 16 Apr 2023 01:50:26 UTC (1,029 KB)"
GPT is becoming a Turing machine: Here are some ways to program it,Computer Science > Computation and Language,[Submitted on 25 Mar 2023],"Authors:Ana Jojic, Zhen Wang, Nebojsa Jojic","Abstract: We demonstrate that, through appropriate prompting, GPT-3 family of models can be triggered to perform iterative behaviours necessary to execute (rather than just write or recall) programs that involve loops, including several popular algorithms found in computer science curricula or software developer interviews. We trigger execution and description of Iterations by Regimenting Self-Attention (IRSA) in one (or a combination) of three ways: 1) Using strong repetitive structure in an example of an execution path of a target program for one particular input, 2) Prompting with fragments of execution paths, and 3) Explicitly forbidding (skipping) self-attention to parts of the generated text. On a dynamic program execution, IRSA leads to larger accuracy gains than replacing the model with the much more powerful GPT-4. IRSA has promising applications in education, as the prompts and responses resemble student assignments in data structures and algorithms classes. Our findings hold implications for evaluating LLMs, which typically target the in-context learning: We show that prompts that may not even cover one full task example can trigger algorithmic behaviour, allowing solving problems previously thought of as hard for LLMs, such as logical puzzles. Consequently, prompt design plays an even more critical role in LLM performance than previously recognized.",Computation and Language (cs.CL),"Submission history
From: Zhen Wang [view email]
[v1] Sat, 25 Mar 2023 00:43:41 UTC (13,288 KB)"
Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT,Computer Science > Computation and Language,"[Submitted on 5 Apr 2023 (v1), last revised 12 Apr 2023 (this version, v5)]","Authors:Tong Xie, Yuwei Wan, Wei Huang, Yufei Zhou, Yixuan Liu, Qingyuan Linghu, Shaozhou Wang, Chunyu Kit, Clara Grazian, Wenjie Zhang, Bram Hoex","Abstract: The amount of data has growing significance in exploring cutting-edge materials and a number of datasets have been generated either by hand or automated approaches. However, the materials science field struggles to effectively utilize the abundance of data, especially in applied disciplines where materials are evaluated based on device performance rather than their properties. This article presents a new natural language processing (NLP) task called structured information inference (SII) to address the complexities of information extraction at the device level in materials science. We accomplished this task by tuning GPT-3 on an existing perovskite solar cell FAIR (Findable, Accessible, Interoperable, Reusable) dataset with 91.8% F1-score and extended the dataset with data published since its release. The produced data is formatted and normalized, enabling its direct utilization as input in subsequent data analysis. This feature empowers materials scientists to develop models by selecting high-quality review articles within their domain. Additionally, we designed experiments to predict the electrical performance of solar cells and design materials or devices with targeted parameters using large language models (LLMs). Our results demonstrate comparable performance to traditional machine learning methods without feature selection, highlighting the potential of LLMs to acquire scientific knowledge and design new materials akin to materials scientists.",Computation and Language (cs.CL),"Submission history
From: Yuwei Wan [view email]
[v1] Wed, 5 Apr 2023 04:01:52 UTC (2,277 KB)
[v2] Thu, 6 Apr 2023 12:08:53 UTC (4,554 KB)
[v3] Mon, 10 Apr 2023 15:53:26 UTC (2,388 KB)
[v4] Tue, 11 Apr 2023 15:44:30 UTC (2,376 KB)
[v5] Wed, 12 Apr 2023 14:06:02 UTC (2,376 KB)"
Garden-Path Traversal within GPT-2,Computer Science > Computation and Language,"[Submitted on 24 May 2022 (v1), last revised 20 Oct 2022 (this version, v2)]","Authors:William Jurayj, William Rudman, Carsten Eickhoff","Abstract: In recent years, large-scale transformer decoders such as the GPT-x family of models have become increasingly popular. Studies examining the behavior of these models tend to focus only on the output of the language modeling head and avoid analysis of the internal states of the transformer decoder. In this study, we present a collection of methods to analyze the hidden states of GPT-2 and use the model's navigation of garden path sentences as a case study. To enable this, we compile the largest currently available dataset of garden path sentences. We show that Manhattan distances and cosine similarities provide more reliable insights compared to established surprisal methods that analyze next-token probabilities computed by a language modeling head. Using these methods, we find that negating tokens have minimal impacts on the model's representations for unambiguous forms of sentences with ambiguity solely over what the object of a verb is, but have a more substantial impact of representations for unambiguous sentences whose ambiguity would stem from the voice of a verb. Further, we find that analyzing the decoder model's hidden states reveals periods of ambiguity that might conclude in a garden path effect but happen not to, whereas surprisal analyses routinely miss this detail.",Computation and Language (cs.CL),"Submission history
From: William Jurayj [view email]
[v1] Tue, 24 May 2022 18:21:58 UTC (7,665 KB)
[v2] Thu, 20 Oct 2022 16:21:06 UTC (7,690 KB)"
Navigating Complexity in Software Engineering: A Prototype for Comparing GPT-n Solutions,Computer Science > Software Engineering,[Submitted on 28 Jan 2023],Authors:Christoph Treude,"Abstract: Navigating the diverse solution spaces of non-trivial software engineering tasks requires a combination of technical knowledge, problem-solving skills, and creativity. With multiple possible solutions available, each with its own set of trade-offs, it is essential for programmers to evaluate the various options and select the one that best suits the specific requirements and constraints of a project. Whether it is choosing from a range of libraries, weighing the pros and cons of different architecture and design solutions, or finding unique ways to fulfill user requirements, the ability to think creatively is crucial for making informed decisions that will result in efficient and effective software. However, the interfaces of current chatbot tools for programmers, such as OpenAI's ChatGPT or GitHub Copilot, are optimized for presenting a single solution, even for complex queries. While other solutions can be requested, they are not displayed by default and are not intuitive to access. In this paper, we present our work-in-progress prototype ""GPTCompare"", which allows programmers to visually compare multiple source code solutions generated by GPT-n models for the same programming-related query by highlighting their similarities and differences.",Software Engineering (cs.SE),"Submission history
From: Christoph Treude [view email]
[v1] Sat, 28 Jan 2023 11:47:03 UTC (244 KB)"
Action-GPT: Leveraging Large-scale Language Models for Improved and Generalized Zero Shot Action Generation,Computer Science > Computer Vision and Pattern Recognition,"[Submitted on 28 Nov 2022 (v1), last revised 7 Mar 2023 (this version, v3)]","Authors:Sai Shashank Kalakonda, Shubh Maheshwari, Ravi Kiran Sarvadevabhatla","Abstract: We introduce Action-GPT, a plug-and-play framework for incorporating Large Language Models (LLMs) into text-based action generation models. Action phrases in current motion capture datasets contain minimal and to-the-point information. By carefully crafting prompts for LLMs, we generate richer and fine-grained descriptions of the action. We show that utilizing these detailed descriptions instead of the original action phrases leads to better alignment of text and motion spaces. We introduce a generic approach compatible with stochastic (e.g. VAE-based) and deterministic (e.g. MotionCLIP) text-to-motion models. In addition, the approach enables multiple text descriptions to be utilized. Our experiments show (i) noticeable qualitative and quantitative improvement in the quality of synthesized motions, (ii) benefits of utilizing multiple LLM-generated descriptions, (iii) suitability of the prompt function, and (iv) zero-shot generation capabilities of the proposed approach. Project page: this https URL",Computer Vision and Pattern Recognition (cs.CV),"Submission history
From: Ravi Kiran Sarvadevabhatla [view email]
[v1] Mon, 28 Nov 2022 17:57:48 UTC (2,416 KB)
[v2] Wed, 30 Nov 2022 13:13:29 UTC (2,417 KB)
[v3] Tue, 7 Mar 2023 06:14:56 UTC (4,514 KB)"
GPT-4 to GPT-3.5:'Hold My Scalpel'--A Look at the Competency of OpenAI's GPT on the Plastic Surgery In-Service Training Exam,Computer Science > Artificial Intelligence,[Submitted on 4 Apr 2023],"Authors:Jonathan D. Freedman, Ian A. Nappier","Abstract: The Plastic Surgery In-Service Training Exam (PSITE) is an important indicator of resident proficiency and serves as a useful benchmark for evaluating OpenAI's GPT. Unlike many of the simulated tests or practice questions shown in the GPT-4 Technical Paper, the multiple-choice questions evaluated here are authentic PSITE questions. These questions offer realistic clinical vignettes that a plastic surgeon commonly encounters in practice and scores highly correlate with passing the written boards required to become a Board Certified Plastic Surgeon. Our evaluation shows dramatic improvement of GPT-4 (without vision) over GPT-3.5 with both the 2022 and 2021 exams respectively increasing the score from 8th to 88th percentile and 3rd to 99th percentile. The final results of the 2023 PSITE are set to be released on April 11, 2023, and this is an exciting moment to continue our research with a fresh exam. Our evaluation pipeline is ready for the moment that the exam is released so long as we have access via OpenAI to the GPT-4 API. With multimodal input, we may achieve superhuman performance on the 2023.",Artificial Intelligence (cs.AI),"Submission history
From: Jonathan Freedman [view email]
[v1] Tue, 4 Apr 2023 03:30:12 UTC (1,141 KB)"
TRScore: A Novel GPT-based Readability Scorer for ASR Segmentation and Punctuation model evaluation and selection,Computer Science > Computation and Language,[Submitted on 27 Oct 2022],"Authors:Piyush Behre, Sharman Tan, Amy Shah, Harini Kesavamoorthy, Shuangyu Chang, Fei Zuo, Chris Basoglu, Sayan Pathak","Abstract: Punctuation and Segmentation are key to readability in Automatic Speech Recognition (ASR), often evaluated using F1 scores that require high-quality human transcripts and do not reflect readability well. Human evaluation is expensive, time-consuming, and suffers from large inter-observer variability, especially in conversational speech devoid of strict grammatical structures. Large pre-trained models capture a notion of grammatical structure. We present TRScore, a novel readability measure using the GPT model to evaluate different segmentation and punctuation systems. We validate our approach with human experts. Additionally, our approach enables quantitative assessment of text post-processing techniques such as capitalization, inverse text normalization (ITN), and disfluency on overall readability, which traditional word error rate (WER) and slot error rate (SER) metrics fail to capture. TRScore is strongly correlated to traditional F1 and human readability scores, with Pearson's correlation coefficients of 0.67 and 0.98, respectively. It also eliminates the need for human transcriptions for model selection.",Computation and Language (cs.CL),"Submission history
From: Piyush Behre [view email]
[v1] Thu, 27 Oct 2022 01:11:32 UTC (20 KB)"
Geotechnical Parrot Tales (GPT): Overcoming GPT hallucinations with prompt engineering for geotechnical applications,Computer Science > Computation and Language,"[Submitted on 4 Apr 2023 (v1), last revised 14 Apr 2023 (this version, v2)]",Authors:Krishna Kumar,"Abstract: The widespread adoption of large language models (LLMs), such as OpenAI's ChatGPT, could revolutionize various industries, including geotechnical engineering. However, GPT models can sometimes generate plausible-sounding but false outputs, leading to hallucinations. In this article, we discuss the importance of prompt engineering in mitigating these risks and harnessing the full potential of GPT for geotechnical applications. We explore the challenges and pitfalls associated with LLMs and highlight the role of context in ensuring accurate and valuable responses. Furthermore, we examine the development of context-specific search engines and the potential of LLMs to become a natural interface for complex tasks, such as data analysis and design. We also develop a unified interface using natural language to handle complex geotechnical engineering tasks and data analysis. By integrating GPT into geotechnical engineering workflows, professionals can streamline their work and develop sustainable and resilient infrastructure systems for the future.",Computation and Language (cs.CL),"Submission history
From: Krishna Kumar [view email]
[v1] Tue, 4 Apr 2023 21:47:41 UTC (677 KB)
[v2] Fri, 14 Apr 2023 01:09:41 UTC (943 KB)"
Blind Judgement: Agent-Based Supreme Court Modelling With GPT,Computer Science > Computation and Language,[Submitted on 12 Jan 2023],Authors:Sil Hamilton,Abstract: We present a novel Transformer-based multi-agent system for simulating the judicial rulings of the 2010-2016 Supreme Court of the United States. We train nine separate models with the respective authored opinions of each supreme justice active ca. 2015 and test the resulting system on 96 real-world cases. We find our system predicts the decisions of the real-world Supreme Court with better-than-random accuracy. We further find a correlation between model accuracy with respect to individual justices and their alignment between legal conservatism & liberalism. Our methods and results hold significance for researchers interested in using language models to simulate politically-charged discourse between multiple agents.,Computation and Language (cs.CL),"Submission history
From: Sil Hamilton [view email]
[v1] Thu, 12 Jan 2023 23:07:55 UTC (47 KB)"
Ten Quick Tips for Harnessing the Power of ChatGPT/GPT-4 in Computational Biology,Quantitative Biology > Other Quantitative Biology,[Submitted on 29 Mar 2023],"Authors:Tiago Lubiana, Rafael Lopes, Pedro Medeiros, Juan Carlo Silva, Andre Nicolau Aquime Goncalves, Vinicius Maracaja-Coutinho, Helder I Nakaya","Abstract: The rise of advanced chatbots, such as ChatGPT, has sparked curiosity in the scientific community. ChatGPT is a general-purpose chatbot powered by large language models (LLMs) GPT-3.5 and GPT-4, with the potential to impact numerous fields, including computational biology. In this article, we offer ten tips based on our experience with ChatGPT to assist computational biologists in optimizing their workflows. We have collected relevant prompts and reviewed the nascent literature in the field, compiling tips we project to remain pertinent for future ChatGPT and LLM iterations, ranging from code refactoring to scientific writing to prompt engineering. We hope our work will help bioinformaticians to complement their workflows while staying aware of the various implications of using this technology. Additionally, to track new and creative applications for bioinformatics tools such as ChatGPT, we have established a GitHub repository at this https URL. Our belief is that ethical adherence to ChatGPT and other LLMs will increase the efficiency of computational biologists, ultimately advancing the pace of scientific discovery in the life sciences.",Other Quantitative Biology (q-bio.OT),"Submission history
From: Tiago Lubiana [view email]
[v1] Wed, 29 Mar 2023 03:24:42 UTC (455 KB)"
Targeted Attack on GPT-Neo for the SATML Language Model Data Extraction Challenge,Computer Science > Computation and Language,[Submitted on 13 Feb 2023],"Authors:Ali Al-Kaswan, Maliheh Izadi, Arie van Deursen","Abstract: Previous work has shown that Large Language Models are susceptible to so-called data extraction attacks. This allows an attacker to extract a sample that was contained in the training data, which has massive privacy implications. The construction of data extraction attacks is challenging, current attacks are quite inefficient, and there exists a significant gap in the extraction capabilities of untargeted attacks and memorization. Thus, targeted attacks are proposed, which identify if a given sample from the training data, is extractable from a model. In this work, we apply a targeted data extraction attack to the SATML2023 Language Model Training Data Extraction Challenge. We apply a two-step approach. In the first step, we maximise the recall of the model and are able to extract the suffix for 69% of the samples. In the second step, we use a classifier-based Membership Inference Attack on the generations. Our AutoSklearn classifier achieves a precision of 0.841. The full approach reaches a score of 0.405 recall at a 10% false positive rate, which is an improvement of 34% over the baseline of 0.301.",Computation and Language (cs.CL),"Submission history
From: Ali Al-Kaswan [view email]
[v1] Mon, 13 Feb 2023 18:00:44 UTC (95 KB)"
A Disability Lens towards Biases in GPT-3 Generated Open-Ended Languages,Computer Science > Computation and Language,[Submitted on 23 Jun 2022],"Authors:Akhter Al Amin, Kazi Sinthia Kabir","Abstract: Language models (LM) are becoming prevalent in many language-based application spaces globally. Although these LMs are improving our day-to-day interactions with digital products, concerns remain whether open-ended languages or text generated from these models reveal any biases toward a specific group of people, thereby risking the usability of a certain product. There is a need to identify whether these models possess bias to improve the fairness in these models. This gap motivates our ongoing work, where we measured the two aspects of bias in GPT-3 generated text through a disability lens.",Computation and Language (cs.CL),"Submission history
From: Akhter Al Amin [view email]
[v1] Thu, 23 Jun 2022 21:57:08 UTC (382 KB)"
A Disability Lens towards Biases in GPT-3 Generated Open-Ended Languages,Computer Science > Computation and Language,[Submitted on 23 Jun 2022],"Authors:Akhter Al Amin, Kazi Sinthia Kabir","Abstract: Language models (LM) are becoming prevalent in many language-based application spaces globally. Although these LMs are improving our day-to-day interactions with digital products, concerns remain whether open-ended languages or text generated from these models reveal any biases toward a specific group of people, thereby risking the usability of a certain product. There is a need to identify whether these models possess bias to improve the fairness in these models. This gap motivates our ongoing work, where we measured the two aspects of bias in GPT-3 generated text through a disability lens.",Computation and Language (cs.CL),"Submission history
From: Akhter Al Amin [view email]
[v1] Thu, 23 Jun 2022 21:57:08 UTC (382 KB)"
Hierarchical GPT with Congruent Transformers for Multi-Sentence Language Models,Computer Science > Computation and Language,[Submitted on 18 Sep 2020],"Authors:Jihyeon Roh, Huiseong Gim, Soo-Young Lee","Abstract: We report a GPT-based multi-sentence language model for dialogue generation and document understanding. First, we propose a hierarchical GPT which consists of three blocks, i.e., a sentence encoding block, a sentence generating block, and a sentence decoding block. The sentence encoding and decoding blocks are basically the encoder-decoder blocks of the standard Transformers, which work on each sentence independently. The sentence generating block is inserted between the encoding and decoding blocks, and generates the next sentence embedding vector from the previous sentence embedding vectors. We believe it is the way human make conversation and understand paragraphs and documents. Since each sentence may consist of fewer words, the sentence encoding and decoding Transformers can use much smaller dimensional embedding vectors. Secondly, we note the attention in the Transformers utilizes the inner-product similarity measure. Therefore, to compare the two vectors in the same space, we set the transform matrices for queries and keys to be the same. Otherwise, the similarity concept is incongruent. We report experimental results to show that these two modifications increase the language model performance for tasks with multiple sentences.",Computation and Language (cs.CL),"Submission history
From: Jihyeon Roh [view email]
[v1] Fri, 18 Sep 2020 05:55:37 UTC (477 KB)"
Few-shot generative conversational query rewriting,Computer Science > Information Retrieval,[Submitted on 9 Jun 2020],"Authors:Shi Yu, Jiahua Liu, Jingqin Yang, Chenyan Xiong, Paul Bennett, Jianfeng Gao, Zhiyuan Liu","Abstract: Conversational query rewriting aims to reformulate a concise conversational query to a fully specified, context-independent query that can be effectively handled by existing information retrieval systems. This paper presents a few-shot generative approach to conversational query rewriting. We develop two methods, based on rules and self-supervised learning, to generate weak supervision data using large amounts of ad hoc search sessions, and to fine-tune GPT-2 to rewrite conversational queries. On the TREC Conversational Assistance Track, our weakly supervised GPT-2 rewriter improves the state-of-the-art ranking accuracy by 12%, only using very limited amounts of manual query rewrites. In the zero-shot learning setting, the rewriter still gives a comparable result to previous state-of-the-art systems. Our analyses reveal that GPT-2 effectively picks up the task syntax and learns to capture context dependencies, even for hard cases that involve group references and long-turn dependencies.",Information Retrieval (cs.IR),"Submission history
From: Jiahua Liu [view email]
[v1] Tue, 9 Jun 2020 01:47:58 UTC (311 KB)"
Improving the Diproche CNL through autoformalization via GPT-3,Computer Science > Computation and Language,[Submitted on 12 Mar 2023],Authors:Merlin Carl,"Abstract: The Diproche system is an automated proof checker for texts written in a controlled fragment of German, designed for didactical applications in classes introducing students to proofs for the first time. The first version of the system used a controlled natural language for which a Prolog formalization routine was written. In this paper, we explore the possibility of prompting large language models for autoformalization in the context of Diproche, with encouraging first results.",Computation and Language (cs.CL),"Submission history
From: Merlin Carl [view email]
[v1] Sun, 12 Mar 2023 20:11:25 UTC (15 KB)"
Lora: Low-rank adaptation of large language models,Computer Science > Computation and Language,"[Submitted on 17 Jun 2021 (v1), last revised 16 Oct 2021 (this version, v2)]","Authors:Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen","Abstract: An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at this https URL.",Computation and Language (cs.CL),"Submission history
From: Edward J. Hu [view email]
[v1] Thu, 17 Jun 2021 17:37:18 UTC (1,791 KB)
[v2] Sat, 16 Oct 2021 18:40:34 UTC (896 KB)"
Visualizing attention in transformer-based language representation models,Computer Science > Human-Computer Interaction,"[Submitted on 4 Apr 2019 (v1), last revised 11 Apr 2019 (this version, v2)]",Authors:Jesse Vig,"Abstract: We present an open-source tool for visualizing multi-head self-attention in Transformer-based language representation models. The tool extends earlier work by visualizing attention at three levels of granularity: the attention-head level, the model level, and the neuron level. We describe how each of these views can help to interpret the model, and we demonstrate the tool on the BERT model and the OpenAI GPT-2 model. We also present three use cases for analyzing GPT-2: detecting model bias, identifying recurring patterns, and linking neurons to model behavior.",Human-Computer Interaction (cs.HC),"Submission history
From: Jesse Vig [view email]
[v1] Thu, 4 Apr 2019 17:32:49 UTC (7,552 KB)
[v2] Thu, 11 Apr 2019 16:00:53 UTC (4,612 KB)"
Persistent anti-muslim bias in large language models,Computer Science > Computation and Language,"[Submitted on 14 Jan 2021 (v1), last revised 18 Jan 2021 (this version, v2)]","Authors:Abubakar Abid, Maheen Farooqi, James Zou","Abstract: It has been observed that large-scale language models capture undesirable societal biases, e.g. relating to race and gender; yet religious bias has been relatively unexplored. We demonstrate that GPT-3, a state-of-the-art contextual language model, captures persistent Muslim-violence bias. We probe GPT-3 in various ways, including prompt completion, analogical reasoning, and story generation, to understand this anti-Muslim bias, demonstrating that it appears consistently and creatively in different uses of the model and that it is severe even compared to biases about other religious groups. For instance, ""Muslim"" is analogized to ""terrorist"" in 23% of test cases, while ""Jewish"" is mapped to ""money"" in 5% of test cases. We quantify the positive distraction needed to overcome this bias with adversarial text prompts, and find that use of the most positive 6 adjectives reduces violent completions for ""Muslims"" from 66% to 20%, but which is still higher than for other religious groups.",Computation and Language (cs.CL),"Submission history
From: Abubakar Abid [view email]
[v1] Thu, 14 Jan 2021 18:41:55 UTC (2,799 KB)
[v2] Mon, 18 Jan 2021 17:02:28 UTC (4,784 KB)"
"GPT Conjecture: Understanding the Trade-offs between Granularity, Performance and Timeliness in Control-Flow Integrity",Computer Science > Cryptography and Security,"[Submitted on 18 Nov 2019 (v1), last revised 10 Jan 2021 (this version, v3)]","Authors:Zhilong Wang, Peng Liu","Abstract: Performance/security trade-off is widely noticed in CFI research, however, we observe that not every CFI scheme is subject to the trade-off. Motivated by the key observation, we ask three questions. Although the three questions probably cannot be directly answered, they are inspiring. We find that a deeper understanding of the nature of the trade-off will help answer the three questions. Accordingly, we proposed the GPT conjecture to pinpoint the trade-off in designing CFI schemes, which says that at most two out of three properties (fine granularity, acceptable performance, and preventive protection) could be achieved.",Cryptography and Security (cs.CR),"Submission history
From: Zhilong Wang [view email]
[v1] Mon, 18 Nov 2019 18:45:16 UTC (224 KB)
[v2] Mon, 25 Nov 2019 22:27:38 UTC (92 KB)
[v3] Sun, 10 Jan 2021 05:08:56 UTC (92 KB)"
Theory of mind may have spontaneously emerged in large language models,Computer Science > Computation and Language,"[Submitted on 4 Feb 2023 (v1), last revised 14 Mar 2023 (this version, v3)]",Authors:Michal Kosinski,"Abstract: Theory of mind (ToM), or the ability to impute unobservable mental states to others, is central to human social interactions, communication, empathy, self-consciousness, and morality. We tested several language models using 40 classic false-belief tasks widely used to test ToM in humans. The models published before 2020 showed virtually no ability to solve ToM tasks. Yet, the first version of GPT-3 (""davinci-001""), published in May 2020, solved about 40% of false-belief tasks-performance comparable with 3.5-year-old children. Its second version (""davinci-002""; January 2022) solved 70% of false-belief tasks, performance comparable with six-year-olds. Its most recent version, GPT-3.5 (""davinci-003""; November 2022), solved 90% of false-belief tasks, at the level of seven-year-olds. GPT-4 published in March 2023 solved nearly all the tasks (95%). These findings suggest that ToM-like ability (thus far considered to be uniquely human) may have spontaneously emerged as a byproduct of language models' improving language skills.",Computation and Language (cs.CL),"Submission history
From: Michal Kosinski [view email]
[v1] Sat, 4 Feb 2023 03:50:01 UTC (539 KB)
[v2] Fri, 10 Feb 2023 19:01:49 UTC (538 KB)
[v3] Tue, 14 Mar 2023 18:49:26 UTC (604 KB)"
A multiscale visualization of attention in the transformer model,Computer Science > Human-Computer Interaction,[Submitted on 12 Jun 2019],Authors:Jesse Vig,"Abstract: The Transformer is a sequence model that forgoes traditional recurrent architectures in favor of a fully attention-based approach. Besides improving performance, an advantage of using attention is that it can also help to interpret a model by showing how the model assigns weight to different input elements. However, the multi-layer, multi-head attention mechanism in the Transformer model can be difficult to decipher. To make the model more accessible, we introduce an open-source tool that visualizes attention at multiple scales, each of which provides a unique perspective on the attention mechanism. We demonstrate the tool on BERT and OpenAI GPT-2 and present three example use cases: detecting model bias, locating relevant attention heads, and linking neurons to model behavior.",Human-Computer Interaction (cs.HC),"Submission history
From: Jesse Vig [view email]
[v1] Wed, 12 Jun 2019 15:45:26 UTC (1,350 KB)"
